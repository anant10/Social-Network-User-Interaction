mvn clean package
[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mcs6240:mr-demo[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding mr-demo 1.0[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
Downloading from dynamodb-local-oregon: https://s3-us-west-2.amazonaws.com/dynamodb-local/release/net/minidev/json-smart/maven-metadata.xml
Downloading from repository.jboss.org: http://repository.jboss.org/nexus/content/groups/public/net/minidev/json-smart/maven-metadata.xml
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/net/minidev/json-smart/maven-metadata.xml
Downloading from central: https://repo.maven.apache.org/maven2/net/minidev/json-smart/maven-metadata.xml
Progress (1): 849 B                   Downloaded from central: https://repo.maven.apache.org/maven2/net/minidev/json-smart/maven-metadata.xml (849 B at 781 B/s)
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-clean-plugin:2.5:clean[m [1m(default-clean)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Deleting /home/pooja/Documents/hadoop_workspace/project-group9/target
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:compile[m [1m(default-compile)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 8 source files to /home/pooja/Documents/hadoop_workspace/project-group9/target/classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/pooja/Documents/hadoop_workspace/project-group9/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:testCompile[m [1m(default-testCompile)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:2.12.4:test[m [1m(default-test)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:2.4:jar[m [1m(default-jar)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/pooja/Documents/hadoop_workspace/project-group9/target/mr-demo-1.0.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.1:shade[m [1m(default)[m @ [36mmr-demo[0;1m ---[m
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/pooja/Documents/hadoop_workspace/project-group9/target/mr-demo-1.0.jar with /home/pooja/Documents/hadoop_workspace/project-group9/target/mr-demo-1.0-shaded.jar
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  9.064 s
[[1;34mINFO[m] Finished at: 2020-11-30T00:05:49-05:00
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
rm -rf output*
/home/pooja/hadoop/hadoop-2.9.1/bin/hadoop jar target/mr-demo-1.0.jar shortestpath.SingleSourceShortestPathRunner input output
20/11/30 00:05:51 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
20/11/30 00:05:51 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
20/11/30 00:05:51 INFO input.FileInputFormat: Total input files to process : 1
20/11/30 00:05:51 INFO mapreduce.JobSubmitter: number of splits:1
20/11/30 00:05:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1912039276_0001
20/11/30 00:05:51 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/11/30 00:05:51 INFO mapreduce.Job: Running job: job_local1912039276_0001
20/11/30 00:05:51 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/11/30 00:05:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:51 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/11/30 00:05:51 INFO mapred.LocalJobRunner: Waiting for map tasks
20/11/30 00:05:51 INFO mapred.LocalJobRunner: Starting task: attempt_local1912039276_0001_m_000000_0
20/11/30 00:05:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:51 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:52 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/stackoverflow.txt:0+62
20/11/30 00:05:52 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:52 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:52 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:52 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:52 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:52 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:52 INFO mapred.LocalJobRunner: 
20/11/30 00:05:52 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:52 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:52 INFO mapred.MapTask: bufstart = 0; bufend = 81; bufvoid = 104857600
20/11/30 00:05:52 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
20/11/30 00:05:52 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:52 INFO mapred.Task: Task:attempt_local1912039276_0001_m_000000_0 is done. And is in the process of committing
20/11/30 00:05:52 INFO mapred.LocalJobRunner: map
20/11/30 00:05:52 INFO mapred.Task: Task 'attempt_local1912039276_0001_m_000000_0' done.
20/11/30 00:05:52 INFO mapred.LocalJobRunner: Finishing task: attempt_local1912039276_0001_m_000000_0
20/11/30 00:05:52 INFO mapred.LocalJobRunner: map task executor complete.
20/11/30 00:05:52 INFO mapred.LocalJobRunner: Waiting for reduce tasks
20/11/30 00:05:52 INFO mapred.LocalJobRunner: Starting task: attempt_local1912039276_0001_r_000000_0
20/11/30 00:05:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:52 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:52 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:52 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1dd2a77f
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
20/11/30 00:05:52 INFO reduce.EventFetcher: attempt_local1912039276_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
20/11/30 00:05:52 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1912039276_0001_m_000000_0 decomp: 101 len: 105 to MEMORY
20/11/30 00:05:52 INFO reduce.InMemoryMapOutput: Read 101 bytes from map-output for attempt_local1912039276_0001_m_000000_0
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->101
20/11/30 00:05:52 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
20/11/30 00:05:52 INFO mapred.LocalJobRunner: 1 / 1 copied.
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
20/11/30 00:05:52 INFO mapred.Merger: Merging 1 sorted segments
20/11/30 00:05:52 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 97 bytes
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: Merged 1 segments, 101 bytes to disk to satisfy reduce memory limit
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: Merging 1 files, 105 bytes from disk
20/11/30 00:05:52 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
20/11/30 00:05:52 INFO mapred.Merger: Merging 1 sorted segments
20/11/30 00:05:52 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 97 bytes
20/11/30 00:05:52 INFO mapred.LocalJobRunner: 1 / 1 copied.
20/11/30 00:05:52 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
20/11/30 00:05:52 INFO mapred.Task: Task:attempt_local1912039276_0001_r_000000_0 is done. And is in the process of committing
20/11/30 00:05:52 INFO mapred.LocalJobRunner: 1 / 1 copied.
20/11/30 00:05:52 INFO mapred.Task: Task attempt_local1912039276_0001_r_000000_0 is allowed to commit now
20/11/30 00:05:52 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1912039276_0001_r_000000_0' to file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/_temporary/0/task_local1912039276_0001_r_000000
20/11/30 00:05:52 INFO mapred.LocalJobRunner: reduce > reduce
20/11/30 00:05:52 INFO mapred.Task: Task 'attempt_local1912039276_0001_r_000000_0' done.
20/11/30 00:05:52 INFO mapred.LocalJobRunner: Finishing task: attempt_local1912039276_0001_r_000000_0
20/11/30 00:05:52 INFO mapred.LocalJobRunner: reduce task executor complete.
20/11/30 00:05:52 INFO mapreduce.Job: Job job_local1912039276_0001 running in uber mode : false
20/11/30 00:05:52 INFO mapreduce.Job:  map 100% reduce 100%
20/11/30 00:05:52 INFO mapreduce.Job: Job job_local1912039276_0001 completed successfully
20/11/30 00:05:52 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=36346
		FILE: Number of bytes written=965150
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=81
		Map output materialized bytes=105
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=105
		Reduce input records=9
		Reduce output records=5
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=525336576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=62
	File Output Format Counters 
		Bytes Written=235
20/11/30 00:05:52 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/11/30 00:05:52 INFO input.FileInputFormat: Total input files to process : 1
20/11/30 00:05:52 INFO mapreduce.JobSubmitter: number of splits:5
20/11/30 00:05:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1957159998_0002
20/11/30 00:05:53 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/11/30 00:05:53 INFO mapreduce.Job: Running job: job_local1957159998_0002
20/11/30 00:05:53 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/11/30 00:05:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:53 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/11/30 00:05:53 INFO mapred.LocalJobRunner: Waiting for map tasks
20/11/30 00:05:53 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_m_000000_0
20/11/30 00:05:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:53 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:65+57
20/11/30 00:05:53 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:53 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:53 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:53 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:53 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:53 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:53 INFO mapred.LocalJobRunner: 
20/11/30 00:05:53 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:53 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:53 INFO mapred.MapTask: bufstart = 0; bufend = 37; bufvoid = 104857600
20/11/30 00:05:53 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:53 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:53 INFO mapred.Task: Task:attempt_local1957159998_0002_m_000000_0 is done. And is in the process of committing
20/11/30 00:05:53 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:65+57
20/11/30 00:05:53 INFO mapred.Task: Task 'attempt_local1957159998_0002_m_000000_0' done.
20/11/30 00:05:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_m_000000_0
20/11/30 00:05:53 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_m_000001_0
20/11/30 00:05:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:53 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:122+57
20/11/30 00:05:55 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:55 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:55 INFO mapreduce.Job: Job job_local1957159998_0002 running in uber mode : false
20/11/30 00:05:55 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:55 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:55 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:55 INFO mapreduce.Job:  map 100% reduce 0%
20/11/30 00:05:55 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:55 INFO mapred.LocalJobRunner: 
20/11/30 00:05:55 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:55 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:55 INFO mapred.MapTask: bufstart = 0; bufend = 37; bufvoid = 104857600
20/11/30 00:05:55 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:55 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:55 INFO mapred.Task: Task:attempt_local1957159998_0002_m_000001_0 is done. And is in the process of committing
20/11/30 00:05:55 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:122+57
20/11/30 00:05:55 INFO mapred.Task: Task 'attempt_local1957159998_0002_m_000001_0' done.
20/11/30 00:05:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_m_000001_0
20/11/30 00:05:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_m_000002_0
20/11/30 00:05:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:55 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:55 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:22+43
20/11/30 00:05:56 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:56 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:56 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:56 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 
20/11/30 00:05:56 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:56 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufend = 23; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:56 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:56 INFO mapred.Task: Task:attempt_local1957159998_0002_m_000002_0 is done. And is in the process of committing
20/11/30 00:05:56 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:22+43
20/11/30 00:05:56 INFO mapred.Task: Task 'attempt_local1957159998_0002_m_000002_0' done.
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_m_000002_0
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_m_000003_0
20/11/30 00:05:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:56 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:56 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:179+43
20/11/30 00:05:56 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:56 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:56 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:56 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 
20/11/30 00:05:56 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:56 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufend = 23; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:56 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:56 INFO mapred.Task: Task:attempt_local1957159998_0002_m_000003_0 is done. And is in the process of committing
20/11/30 00:05:56 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:179+43
20/11/30 00:05:56 INFO mapred.Task: Task 'attempt_local1957159998_0002_m_000003_0' done.
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_m_000003_0
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_m_000004_0
20/11/30 00:05:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:56 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:56 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:0+22
20/11/30 00:05:56 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:56 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:56 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:56 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 
20/11/30 00:05:56 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:56 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:56 INFO mapred.MapTask: bufstart = 0; bufend = 40; bufvoid = 104857600
20/11/30 00:05:56 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
20/11/30 00:05:56 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:56 INFO mapred.Task: Task:attempt_local1957159998_0002_m_000004_0 is done. And is in the process of committing
20/11/30 00:05:56 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder0/part-r-00000:0+22
20/11/30 00:05:56 INFO mapred.Task: Task 'attempt_local1957159998_0002_m_000004_0' done.
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_m_000004_0
20/11/30 00:05:56 INFO mapred.LocalJobRunner: map task executor complete.
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Waiting for reduce tasks
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1957159998_0002_r_000000_0
20/11/30 00:05:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:56 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:56 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@256e02e8
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
20/11/30 00:05:56 INFO reduce.EventFetcher: attempt_local1957159998_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
20/11/30 00:05:56 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1957159998_0002_m_000004_0 decomp: 46 len: 50 to MEMORY
20/11/30 00:05:56 INFO reduce.InMemoryMapOutput: Read 46 bytes from map-output for attempt_local1957159998_0002_m_000004_0
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 46, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->46
20/11/30 00:05:56 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/30 00:05:56 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1957159998_0002_m_000003_0 decomp: 27 len: 31 to MEMORY
20/11/30 00:05:56 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local1957159998_0002_m_000003_0
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 2, commitMemory -> 46, usedMemory ->73
20/11/30 00:05:56 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/30 00:05:56 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1957159998_0002_m_000000_0 decomp: 41 len: 45 to MEMORY
20/11/30 00:05:56 INFO reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1957159998_0002_m_000000_0
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 73, usedMemory ->114
20/11/30 00:05:56 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1957159998_0002_m_000002_0 decomp: 27 len: 31 to MEMORY
20/11/30 00:05:56 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local1957159998_0002_m_000002_0
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 4, commitMemory -> 114, usedMemory ->141
20/11/30 00:05:56 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/30 00:05:56 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1957159998_0002_m_000001_0 decomp: 41 len: 45 to MEMORY
20/11/30 00:05:56 INFO reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1957159998_0002_m_000001_0
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 5, commitMemory -> 141, usedMemory ->182
20/11/30 00:05:56 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
20/11/30 00:05:56 INFO mapred.Merger: Merging 5 sorted segments
20/11/30 00:05:56 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 162 bytes
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: Merged 5 segments, 182 bytes to disk to satisfy reduce memory limit
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: Merging 1 files, 178 bytes from disk
20/11/30 00:05:56 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
20/11/30 00:05:56 INFO mapred.Merger: Merging 1 sorted segments
20/11/30 00:05:56 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 170 bytes
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:56 INFO mapred.Task: Task:attempt_local1957159998_0002_r_000000_0 is done. And is in the process of committing
20/11/30 00:05:56 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:56 INFO mapred.Task: Task attempt_local1957159998_0002_r_000000_0 is allowed to commit now
20/11/30 00:05:56 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1957159998_0002_r_000000_0' to file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/_temporary/0/task_local1957159998_0002_r_000000
20/11/30 00:05:56 INFO mapred.LocalJobRunner: reduce > reduce
20/11/30 00:05:56 INFO mapred.Task: Task 'attempt_local1957159998_0002_r_000000_0' done.
20/11/30 00:05:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1957159998_0002_r_000000_0
20/11/30 00:05:56 INFO mapred.LocalJobRunner: reduce task executor complete.
20/11/30 00:05:57 INFO mapreduce.Job:  map 100% reduce 100%
20/11/30 00:05:57 INFO mapreduce.Job: Job job_local1957159998_0002 completed successfully
20/11/30 00:05:57 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=237976
		FILE: Number of bytes written=5793796
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=6
		Map output bytes=160
		Map output materialized bytes=202
		Input split bytes=750
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=202
		Reduce input records=6
		Reduce output records=5
		Spilled Records=12
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=494
		Total committed heap usage (bytes)=2145386496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1195
	File Output Format Counters 
		Bytes Written=216
	shortestpath.SingleSourceShortestPathRunner$SSSPCounter
		ITERATION=1
20/11/30 00:05:57 INFO shortestpath.SingleSourceShortestPathRunner: iterCount 1
20/11/30 00:05:57 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/11/30 00:05:57 INFO input.FileInputFormat: Total input files to process : 1
20/11/30 00:05:57 INFO mapreduce.JobSubmitter: number of splits:5
20/11/30 00:05:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local644650016_0003
20/11/30 00:05:58 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/11/30 00:05:58 INFO mapreduce.Job: Running job: job_local644650016_0003
20/11/30 00:05:58 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/11/30 00:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:58 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Waiting for map tasks
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_m_000000_0
20/11/30 00:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:58 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:103+57
20/11/30 00:05:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:58 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:58 INFO mapred.LocalJobRunner: 
20/11/30 00:05:58 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:58 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufend = 37; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:58 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:58 INFO mapred.Task: Task:attempt_local644650016_0003_m_000000_0 is done. And is in the process of committing
20/11/30 00:05:58 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:103+57
20/11/30 00:05:58 INFO mapred.Task: Task 'attempt_local644650016_0003_m_000000_0' done.
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_m_000000_0
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_m_000001_0
20/11/30 00:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:58 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:22+43
20/11/30 00:05:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:58 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:58 INFO mapred.LocalJobRunner: 
20/11/30 00:05:58 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:58 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufend = 23; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:58 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:58 INFO mapred.Task: Task:attempt_local644650016_0003_m_000001_0 is done. And is in the process of committing
20/11/30 00:05:58 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:22+43
20/11/30 00:05:58 INFO mapred.Task: Task 'attempt_local644650016_0003_m_000001_0' done.
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_m_000001_0
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_m_000002_0
20/11/30 00:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:58 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:160+43
20/11/30 00:05:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:58 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:58 INFO mapred.LocalJobRunner: 
20/11/30 00:05:58 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:58 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:58 INFO mapred.MapTask: bufstart = 0; bufend = 23; bufvoid = 104857600
20/11/30 00:05:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:58 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:58 INFO mapred.Task: Task:attempt_local644650016_0003_m_000002_0 is done. And is in the process of committing
20/11/30 00:05:58 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:160+43
20/11/30 00:05:58 INFO mapred.Task: Task 'attempt_local644650016_0003_m_000002_0' done.
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_m_000002_0
20/11/30 00:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_m_000003_0
20/11/30 00:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:58 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:65+38
20/11/30 00:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:59 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 
20/11/30 00:05:59 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:59 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufend = 88; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
20/11/30 00:05:59 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local644650016_0003_m_000003_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:65+38
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local644650016_0003_m_000003_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_m_000003_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_m_000004_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:0+22
20/11/30 00:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:59 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 
20/11/30 00:05:59 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:59 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufend = 40; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
20/11/30 00:05:59 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local644650016_0003_m_000004_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder1/part-r-00000:0+22
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local644650016_0003_m_000004_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_m_000004_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: map task executor complete.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Waiting for reduce tasks
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local644650016_0003_r_000000_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54e0d8d9
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
20/11/30 00:05:59 INFO reduce.EventFetcher: attempt_local644650016_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
20/11/30 00:05:59 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local644650016_0003_m_000004_0 decomp: 46 len: 50 to MEMORY
20/11/30 00:05:59 INFO reduce.InMemoryMapOutput: Read 46 bytes from map-output for attempt_local644650016_0003_m_000004_0
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 46, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->46
20/11/30 00:05:59 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local644650016_0003_m_000001_0 decomp: 27 len: 31 to MEMORY
20/11/30 00:05:59 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local644650016_0003_m_000001_0
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 2, commitMemory -> 46, usedMemory ->73
20/11/30 00:05:59 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local644650016_0003_m_000003_0 decomp: 98 len: 102 to MEMORY
20/11/30 00:05:59 INFO reduce.InMemoryMapOutput: Read 98 bytes from map-output for attempt_local644650016_0003_m_000003_0
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 3, commitMemory -> 73, usedMemory ->171
20/11/30 00:05:59 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local644650016_0003_m_000000_0 decomp: 41 len: 45 to MEMORY
20/11/30 00:05:59 INFO reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local644650016_0003_m_000000_0
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 4, commitMemory -> 171, usedMemory ->212
20/11/30 00:05:59 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local644650016_0003_m_000002_0 decomp: 27 len: 31 to MEMORY
20/11/30 00:05:59 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local644650016_0003_m_000002_0
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 5, commitMemory -> 212, usedMemory ->239
20/11/30 00:05:59 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
20/11/30 00:05:59 INFO mapred.Merger: Merging 5 sorted segments
20/11/30 00:05:59 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 219 bytes
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: Merged 5 segments, 239 bytes to disk to satisfy reduce memory limit
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: Merging 1 files, 235 bytes from disk
20/11/30 00:05:59 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
20/11/30 00:05:59 INFO mapred.Merger: Merging 1 sorted segments
20/11/30 00:05:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 227 bytes
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local644650016_0003_r_000000_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:05:59 INFO mapred.Task: Task attempt_local644650016_0003_r_000000_0 is allowed to commit now
20/11/30 00:05:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_local644650016_0003_r_000000_0' to file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/_temporary/0/task_local644650016_0003_r_000000
20/11/30 00:05:59 INFO mapred.LocalJobRunner: reduce > reduce
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local644650016_0003_r_000000_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local644650016_0003_r_000000_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: reduce task executor complete.
20/11/30 00:05:59 INFO mapreduce.Job: Job job_local644650016_0003 running in uber mode : false
20/11/30 00:05:59 INFO mapreduce.Job:  map 100% reduce 100%
20/11/30 00:05:59 INFO mapreduce.Job: Job job_local644650016_0003 completed successfully
20/11/30 00:05:59 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=376580
		FILE: Number of bytes written=8680543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=9
		Map output bytes=211
		Map output materialized bytes=259
		Input split bytes=750
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=259
		Reduce input records=9
		Reduce output records=5
		Spilled Records=18
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=112
		Total committed heap usage (bytes)=2016411648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1100
	File Output Format Counters 
		Bytes Written=175
	shortestpath.SingleSourceShortestPathRunner$SSSPCounter
		ITERATION=2
20/11/30 00:05:59 INFO shortestpath.SingleSourceShortestPathRunner: iterCount 2
20/11/30 00:05:59 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/11/30 00:05:59 INFO input.FileInputFormat: Total input files to process : 1
20/11/30 00:05:59 INFO mapreduce.JobSubmitter: number of splits:5
20/11/30 00:05:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1149957595_0004
20/11/30 00:05:59 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/11/30 00:05:59 INFO mapreduce.Job: Running job: job_local1149957595_0004
20/11/30 00:05:59 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Waiting for map tasks
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_m_000000_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:119+43
20/11/30 00:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:59 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 
20/11/30 00:05:59 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:59 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufend = 23; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:05:59 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local1149957595_0004_m_000000_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:119+43
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local1149957595_0004_m_000000_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_m_000000_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_m_000001_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:43+38
20/11/30 00:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:59 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 
20/11/30 00:05:59 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:59 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufend = 88; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
20/11/30 00:05:59 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local1149957595_0004_m_000001_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:43+38
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local1149957595_0004_m_000001_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_m_000001_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_m_000002_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:81+38
20/11/30 00:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:05:59 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:05:59 INFO mapred.LocalJobRunner: 
20/11/30 00:05:59 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:05:59 INFO mapred.MapTask: Spilling map output
20/11/30 00:05:59 INFO mapred.MapTask: bufstart = 0; bufend = 88; bufvoid = 104857600
20/11/30 00:05:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
20/11/30 00:05:59 INFO mapred.MapTask: Finished spill 0
20/11/30 00:05:59 INFO mapred.Task: Task:attempt_local1149957595_0004_m_000002_0 is done. And is in the process of committing
20/11/30 00:05:59 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:81+38
20/11/30 00:05:59 INFO mapred.Task: Task 'attempt_local1149957595_0004_m_000002_0' done.
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_m_000002_0
20/11/30 00:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_m_000003_0
20/11/30 00:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:05:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:05:59 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:19+24
20/11/30 00:06:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:06:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:06:00 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:06:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:06:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:06:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:06:00 INFO mapred.LocalJobRunner: 
20/11/30 00:06:00 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:06:00 INFO mapred.MapTask: Spilling map output
20/11/30 00:06:00 INFO mapred.MapTask: bufstart = 0; bufend = 40; bufvoid = 104857600
20/11/30 00:06:00 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
20/11/30 00:06:00 INFO mapred.MapTask: Finished spill 0
20/11/30 00:06:00 INFO mapred.Task: Task:attempt_local1149957595_0004_m_000003_0 is done. And is in the process of committing
20/11/30 00:06:00 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:19+24
20/11/30 00:06:00 INFO mapred.Task: Task 'attempt_local1149957595_0004_m_000003_0' done.
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_m_000003_0
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_m_000004_0
20/11/30 00:06:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:06:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:06:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:06:00 INFO mapred.MapTask: Processing split: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:0+19
20/11/30 00:06:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/11/30 00:06:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/11/30 00:06:00 INFO mapred.MapTask: soft limit at 83886080
20/11/30 00:06:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/11/30 00:06:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/11/30 00:06:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/11/30 00:06:00 INFO mapred.LocalJobRunner: 
20/11/30 00:06:00 INFO mapred.MapTask: Starting flush of map output
20/11/30 00:06:00 INFO mapred.MapTask: Spilling map output
20/11/30 00:06:00 INFO mapred.MapTask: bufstart = 0; bufend = 17; bufvoid = 104857600
20/11/30 00:06:00 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
20/11/30 00:06:00 INFO mapred.MapTask: Finished spill 0
20/11/30 00:06:00 INFO mapred.Task: Task:attempt_local1149957595_0004_m_000004_0 is done. And is in the process of committing
20/11/30 00:06:00 INFO mapred.LocalJobRunner: file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder2/part-r-00000:0+19
20/11/30 00:06:00 INFO mapred.Task: Task 'attempt_local1149957595_0004_m_000004_0' done.
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_m_000004_0
20/11/30 00:06:00 INFO mapred.LocalJobRunner: map task executor complete.
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Waiting for reduce tasks
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1149957595_0004_r_000000_0
20/11/30 00:06:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
20/11/30 00:06:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/11/30 00:06:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/11/30 00:06:00 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44528d9d
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
20/11/30 00:06:00 INFO reduce.EventFetcher: attempt_local1149957595_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
20/11/30 00:06:00 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1149957595_0004_m_000002_0 decomp: 98 len: 102 to MEMORY
20/11/30 00:06:00 INFO reduce.InMemoryMapOutput: Read 98 bytes from map-output for attempt_local1149957595_0004_m_000002_0
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
20/11/30 00:06:00 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1149957595_0004_m_000001_0 decomp: 98 len: 102 to MEMORY
20/11/30 00:06:00 INFO reduce.InMemoryMapOutput: Read 98 bytes from map-output for attempt_local1149957595_0004_m_000001_0
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 2, commitMemory -> 98, usedMemory ->196
20/11/30 00:06:00 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1149957595_0004_m_000004_0 decomp: 21 len: 25 to MEMORY
20/11/30 00:06:00 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local1149957595_0004_m_000004_0
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 3, commitMemory -> 196, usedMemory ->217
20/11/30 00:06:00 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1149957595_0004_m_000000_0 decomp: 27 len: 31 to MEMORY
20/11/30 00:06:00 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local1149957595_0004_m_000000_0
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 4, commitMemory -> 217, usedMemory ->244
20/11/30 00:06:00 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/30 00:06:00 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1149957595_0004_m_000003_0 decomp: 46 len: 50 to MEMORY
20/11/30 00:06:00 INFO reduce.InMemoryMapOutput: Read 46 bytes from map-output for attempt_local1149957595_0004_m_000003_0
20/11/30 00:06:00 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 46, inMemoryMapOutputs.size() -> 5, commitMemory -> 244, usedMemory ->290
20/11/30 00:06:00 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
20/11/30 00:06:00 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
20/11/30 00:06:00 INFO mapred.Merger: Merging 5 sorted segments
20/11/30 00:06:00 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 270 bytes
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: Merged 5 segments, 290 bytes to disk to satisfy reduce memory limit
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: Merging 1 files, 286 bytes from disk
20/11/30 00:06:00 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
20/11/30 00:06:00 INFO mapred.Merger: Merging 1 sorted segments
20/11/30 00:06:00 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 278 bytes
20/11/30 00:06:00 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:06:00 INFO mapred.Task: Task:attempt_local1149957595_0004_r_000000_0 is done. And is in the process of committing
20/11/30 00:06:00 INFO mapred.LocalJobRunner: 5 / 5 copied.
20/11/30 00:06:00 INFO mapred.Task: Task attempt_local1149957595_0004_r_000000_0 is allowed to commit now
20/11/30 00:06:00 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1149957595_0004_r_000000_0' to file:/home/pooja/Documents/hadoop_workspace/project-group9/input/folder3/_temporary/0/task_local1149957595_0004_r_000000
20/11/30 00:06:00 INFO mapred.LocalJobRunner: reduce > reduce
20/11/30 00:06:00 INFO mapred.Task: Task 'attempt_local1149957595_0004_r_000000_0' done.
20/11/30 00:06:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1149957595_0004_r_000000_0
20/11/30 00:06:00 INFO mapred.LocalJobRunner: reduce task executor complete.
20/11/30 00:06:00 INFO mapreduce.Job: Job job_local1149957595_0004 running in uber mode : false
20/11/30 00:06:00 INFO mapreduce.Job:  map 100% reduce 100%
20/11/30 00:06:00 INFO mapreduce.Job: Job job_local1149957595_0004 completed successfully
20/11/30 00:06:00 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=514600
		FILE: Number of bytes written=11581319
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=256
		Map output materialized bytes=310
		Input split bytes=750
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=310
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=2197291008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=895
	File Output Format Counters 
		Bytes Written=97
20/11/30 00:06:00 INFO shortestpath.SingleSourceShortestPathRunner: iterCount 0
